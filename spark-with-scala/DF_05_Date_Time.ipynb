{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date et Time - Manipulation de la date et l'heure\n",
    "Voyons un aperçu de la date et de l'heure en utilisant les fonctions disponibles.\n",
    "* Nous pouvons utiliser `current_date` pour obtenir la date du serveur d'aujourd'hui.\n",
    " * La date sera renvoyée au format **aaaa-MM-jj**.\n",
    "* Nous pouvons utiliser `current_timestamp` pour obtenir l'heure actuelle du serveur.\n",
    " * L'horodatage sera renvoyé au format **aaaa-MM-jj HH:mm:ss.SSS**.\n",
    " * Les heures seront par défaut au format 24 heures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [dummy: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[dummy: string]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = List(\"X\").toDF(\"dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{current_date, current_timestamp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|current_date|\n",
      "+------------+\n",
      "|  2023-10-20|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(current_date.alias(\"current_date\")).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|current_time           |\n",
      "+-----------------------+\n",
      "|2023-10-20 11:09:30.195|\n",
      "+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(current_timestamp.alias(\"current_time\")).show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date et Time - Arithmétique\n",
    "Effectuons l'arithmétique de la date et de l'heure à l'aide des fonctions pertinentes.\n",
    "* Ajout de jours à une date ou à un horodatage - `date_add`\n",
    "* Soustraire des jours d'une date ou d'un horodatage - `date_sub`\n",
    "* Obtenir la différence entre 2 dates ou horodatages - `datediff`\n",
    "* Obtenir un nombre de mois entre 2 dates ou horodatages - `months_between`\n",
    "* Ajout de mois à une date ou à un horodatage - `add_months`\n",
    "* Obtenir le jour suivant à partir d'une date donnée - `next_day`\n",
    "* Toutes les fonctions sont explicites. Nous pouvons les appliquer à la date ou à l'horodatage standard. Toutes les fonctions renvoient la date même lorsqu'elles sont appliquées sur le champ d'horodatage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application\n",
    "\n",
    "Effectuons quelques traitements liées à l'arithmétique des dates.\n",
    "* Obtenez d'abord de l'aide sur chaque fonction pour savoir les arguments qui doivent être passés.\n",
    "* Créez un Dataframe nommé datetimesDF avec des colonnes date et heure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetimes = List((2014-02-28,2014-02-28 10:00:00.123), (2016-02-29,2016-02-29 08:08:08.999), (2017-10-31,2017-12-31 11:59:59.123), (2019-11-30,2019-08-31 00:00:00.000))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "List((2014-02-28,2014-02-28 10:00:00.123), (2016-02-29,2016-02-29 08:08:08.999), (2017-10-31,2017-12-31 11:59:59.123), (2019-11-30,2019-08-31 00:00:00.000))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datetimes = List((\"2014-02-28\", \"2014-02-28 10:00:00.123\"),\n",
    "                     (\"2016-02-29\", \"2016-02-29 08:08:08.999\"),\n",
    "                     (\"2017-10-31\", \"2017-12-31 11:59:59.123\"),\n",
    "                     (\"2019-11-30\", \"2019-08-31 00:00:00.000\")\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetimesDF = [date: string, time: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[date: string, time: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datetimesDF = datetimes.toDF(\"date\", \"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+\n",
      "|date      |time                   |\n",
      "+----------+-----------------------+\n",
      "|2014-02-28|2014-02-28 10:00:00.123|\n",
      "|2016-02-29|2016-02-29 08:08:08.999|\n",
      "|2017-10-31|2017-12-31 11:59:59.123|\n",
      "|2019-11-30|2019-08-31 00:00:00.000|\n",
      "+----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimesDF.show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ajoutez 10 jours aux valeurs de date et d'heure.\n",
    "* Soustrayez 10 jours des valeurs de date et d'heure.\n",
    "* Obtenez la différence entre les valeurs current_date et date ainsi que les valeurs current_timestamp et time.\n",
    "* Obtenez le nombre de mois entre les valeurs current_date et date ainsi que les valeurs current_timestamp et time.\n",
    "* Ajoutez 3 mois aux valeurs de date ainsi qu'aux valeurs d'heure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "Unknown Error",
     "evalue": "<console>:26: error: stable identifier required, but spark.implicits found.\n       import spark.implicits._\n                    ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "Unknown Error",
     "evalue": "<console>:34: error: not found: value date_add\n           withColumn(\"date_add_date\", date_add($\"date\", 10)).\n                                       ^\n<console>:35: error: not found: value date_add\n           withColumn(\"date_add_time\", date_add($\"time\", 10)).\n                                       ^\n<console>:36: error: not found: value date_sub\n           withColumn(\"date_sub_date\", date_sub($\"date\", 10)).\n                                       ^\n<console>:37: error: not found: value date_sub\n           withColumn(\"date_sub_time\", date_sub($\"time\", 10)).\n                                       ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "datetimesDF.\n",
    "    withColumn(\"date_add_date\", date_add($\"date\", 10)).\n",
    "    withColumn(\"date_add_time\", date_add($\"time\", 10)).\n",
    "    withColumn(\"date_sub_date\", date_sub($\"date\", 10)).\n",
    "    withColumn(\"date_sub_time\", date_sub($\"time\", 10)).\n",
    "    show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{current_date, current_timestamp, datediff}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+-------------+-------------+\n",
      "|date      |time                   |datediff_date|datediff_time|\n",
      "+----------+-----------------------+-------------+-------------+\n",
      "|2014-02-28|2014-02-28 10:00:00.123|3170         |3170         |\n",
      "|2016-02-29|2016-02-29 08:08:08.999|2439         |2439         |\n",
      "|2017-10-31|2017-12-31 11:59:59.123|1829         |1768         |\n",
      "|2019-11-30|2019-08-31 00:00:00.000|1069         |1160         |\n",
      "+----------+-----------------------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimesDF.\n",
    "    withColumn(\"datediff_date\", datediff(current_date, $\"date\")).\n",
    "    withColumn(\"datediff_time\", datediff(current_timestamp, $\"time\")).\n",
    "    show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{months_between, add_months, round}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+-------------------+-------------------+---------------+---------------+\n",
      "|date      |time                   |months_between_date|months_between_time|add_months_date|add_months_time|\n",
      "+----------+-----------------------+-------------------+-------------------+---------------+---------------+\n",
      "|2014-02-28|2014-02-28 10:00:00.123|104.19             |104.2              |2014-05-28     |2014-05-28     |\n",
      "|2016-02-29|2016-02-29 08:08:08.999|80.16              |80.17              |2016-05-29     |2016-05-29     |\n",
      "|2017-10-31|2017-12-31 11:59:59.123|60.1               |58.1               |2018-01-31     |2018-03-31     |\n",
      "|2019-11-30|2019-08-31 00:00:00.000|35.13              |38.12              |2020-02-29     |2019-11-30     |\n",
      "+----------+-----------------------+-------------------+-------------------+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimesDF.\n",
    "    withColumn(\"months_between_date\", round(months_between(current_date, $\"date\"), 2)).\n",
    "    withColumn(\"months_between_time\", round(months_between(current_timestamp, $\"time\"), 2)).  \n",
    "    withColumn(\"add_months_date\", add_months($\"date\", 3)).\n",
    "    withColumn(\"add_months_time\", add_months($\"time\", 3)).\n",
    "    show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date et Time - trunc et date_trunc\n",
    "\n",
    "* Nous pouvons utiliser `trunc` ou `date_trunc` pour obtenir la date de début de la semaine, du mois, de l'année en cours, etc. en lui transmettant la date ou l'horodatage.\n",
    "* Nous pouvons utiliser `trunc` pour obtenir la date de début du mois ou de l'année en lui transmettant la date ou l'horodatage \n",
    "    - par exemple `trunc(current_date(), \"MM\")` donnera le premier du mois en cours.\n",
    "* Nous pouvons utiliser `date_trunc` pour obtenir la date de début du mois ou de l'année ainsi que l'heure de début de la journée ou de l'heure en lui transmettant l'horodatage.\n",
    " * Obtenir la date de début basée sur le mois - `date_trunc(\"MM\", current_timestamp())`\n",
    " * Obtenir l'heure de début en fonction du jour - `date_trunc(\"DAY\", current_timestamp())`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications\n",
    "\n",
    "Effectuons quelques applications pour comprendre trunc et date_trunc en détail.\n",
    "* Créez un Dataframe nommé datetimesDF avec des colonnes date et heure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetimes = List((2014-02-28,2014-02-28 10:00:00.123), (2016-02-29,2016-02-29 08:08:08.999), (2017-10-31,2017-12-31 11:59:59.123), (2019-11-30,2019-08-31 00:00:00.000))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "List((2014-02-28,2014-02-28 10:00:00.123), (2016-02-29,2016-02-29 08:08:08.999), (2017-10-31,2017-12-31 11:59:59.123), (2019-11-30,2019-08-31 00:00:00.000))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datetimes = List((\"2014-02-28\", \"2014-02-28 10:00:00.123\"),\n",
    "                     (\"2016-02-29\", \"2016-02-29 08:08:08.999\"),\n",
    "                     (\"2017-10-31\", \"2017-12-31 11:59:59.123\"),\n",
    "                     (\"2019-11-30\", \"2019-08-31 00:00:00.000\")\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetimesDF = [date: string, time: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[date: string, time: string]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datetimesDF = datetimes.toDF(\"date\", \"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+\n",
      "|date      |time                   |\n",
      "+----------+-----------------------+\n",
      "|2014-02-28|2014-02-28 10:00:00.123|\n",
      "|2016-02-29|2016-02-29 08:08:08.999|\n",
      "|2017-10-31|2017-12-31 11:59:59.123|\n",
      "|2019-11-30|2019-08-31 00:00:00.000|\n",
      "+----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimesDF.show(truncate=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Obtenez la date de début du mois  en utilisant le champ de date et la date de début de l'année en utilisant le champ d'heure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "Unknown Error",
     "evalue": "<console>:26: error: stable identifier required, but spark.implicits found.\n       import spark.implicits._\n                    ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.trunc\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+----------+----------+\n",
      "|date      |time                   |date_trunc|time_trunc|\n",
      "+----------+-----------------------+----------+----------+\n",
      "|2014-02-28|2014-02-28 10:00:00.123|2014-02-01|2014-01-01|\n",
      "|2016-02-29|2016-02-29 08:08:08.999|2016-02-01|2016-01-01|\n",
      "|2017-10-31|2017-12-31 11:59:59.123|2017-10-01|2017-01-01|\n",
      "|2019-11-30|2019-08-31 00:00:00.000|2019-11-01|2019-01-01|\n",
      "+----------+-----------------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimesDF.\n",
    "    withColumn(\"date_trunc\", trunc($\"date\", \"MM\")).\n",
    "    withColumn(\"time_trunc\", trunc($\"time\", \"yyyy\")).\n",
    "    show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Obtenez l'heure de début en utilisant le champ date et heure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.date_trunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+-------------------+-------------------+\n",
      "|date      |time                   |date_dt            |time_dt            |\n",
      "+----------+-----------------------+-------------------+-------------------+\n",
      "|2014-02-28|2014-02-28 10:00:00.123|2014-02-28 00:00:00|2014-02-28 10:00:00|\n",
      "|2016-02-29|2016-02-29 08:08:08.999|2016-02-29 00:00:00|2016-02-29 08:00:00|\n",
      "|2017-10-31|2017-12-31 11:59:59.123|2017-10-31 00:00:00|2017-12-31 11:00:00|\n",
      "|2019-11-30|2019-08-31 00:00:00.000|2019-11-30 00:00:00|2019-08-31 00:00:00|\n",
      "+----------+-----------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimesDF.\n",
    "    withColumn(\"date_dt\", date_trunc(\"HOUR\", $\"date\")).\n",
    "    withColumn(\"time_dt\", date_trunc(\"HOUR\", $\"time\")).\n",
    "    show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date et heure - Extraction d'informations\n",
    "\n",
    "Comprenons comment extraire des informations à partir de dates ou d'heures à l'aide de fonctions.\n",
    "\n",
    "* Nous pouvons utiliser date_format pour extraire les informations requises dans un format souhaité à partir de la date ou de l'horodatage (timestamp).\n",
    "* Il existe également des fonctions spécifiques pour extraire l'année, le mois, le jour dans une semaine, un jour dans un mois, le jour dans une année, etc.\n",
    "\n",
    "### Applications\n",
    "\n",
    "Effectuons quelques applications pour extraire les informations dont nous avons besoin à partir de la date ou de l'horodatage.\n",
    "\n",
    "* Créez un Dataframe nommé datetimesDF avec des colonnes date et heure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetimes = List((2014-02-28,2014-02-28 10:00:00.123), (2016-02-29,2016-02-29 08:08:08.999), (2017-10-31,2017-12-31 11:59:59.123), (2019-11-30,2019-08-31 00:00:00.000))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "List((2014-02-28,2014-02-28 10:00:00.123), (2016-02-29,2016-02-29 08:08:08.999), (2017-10-31,2017-12-31 11:59:59.123), (2019-11-30,2019-08-31 00:00:00.000))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datetimes = List((\"2014-02-28\", \"2014-02-28 10:00:00.123\"),\n",
    "                     (\"2016-02-29\", \"2016-02-29 08:08:08.999\"),\n",
    "                     (\"2017-10-31\", \"2017-12-31 11:59:59.123\"),\n",
    "                     (\"2019-11-30\", \"2019-08-31 00:00:00.000\")\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetimesDF = [date: string, time: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[date: string, time: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datetimesDF = datetimes.toDF(\"date\", \"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+\n",
      "|date      |time                   |\n",
      "+----------+-----------------------+\n",
      "|2014-02-28|2014-02-28 10:00:00.123|\n",
      "|2016-02-29|2016-02-29 08:08:08.999|\n",
      "|2017-10-31|2017-12-31 11:59:59.123|\n",
      "|2019-11-30|2019-08-31 00:00:00.000|\n",
      "+----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimesDF.show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Obtenez l'année à partir des champs date et heure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+---------+---------+\n",
      "|date      |time                   |date_year|time_year|\n",
      "+----------+-----------------------+---------+---------+\n",
      "|2014-02-28|2014-02-28 10:00:00.123|2014     |2014     |\n",
      "|2016-02-29|2016-02-29 08:08:08.999|2016     |2016     |\n",
      "|2017-10-31|2017-12-31 11:59:59.123|2017     |2017     |\n",
      "|2019-11-30|2019-08-31 00:00:00.000|2019     |2019     |\n",
      "+----------+-----------------------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimesDF.\n",
    "    withColumn(\"date_year\", year($\"date\")).\n",
    "    withColumn(\"time_year\", year($\"time\")).\n",
    "    show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Obtenez le mois (à un ou deux chiffres) à partir des champs date et heure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+----------+----------+\n",
      "|date      |time                   |date_month|time_month|\n",
      "+----------+-----------------------+----------+----------+\n",
      "|2014-02-28|2014-02-28 10:00:00.123|2         |2         |\n",
      "|2016-02-29|2016-02-29 08:08:08.999|2         |2         |\n",
      "|2017-10-31|2017-12-31 11:59:59.123|10        |12        |\n",
      "|2019-11-30|2019-08-31 00:00:00.000|11        |8         |\n",
      "+----------+-----------------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimesDF.\n",
    "    withColumn(\"date_month\", month($\"date\")).\n",
    "    withColumn(\"time_month\", month($\"time\")).\n",
    "    show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Obtenez l'année et le mois au format yyyyMM à partir de la date et de l'heure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+-------+-------+\n",
      "|date      |time                   |date_ym|time_ym|\n",
      "+----------+-----------------------+-------+-------+\n",
      "|2014-02-28|2014-02-28 10:00:00.123|201402 |201402 |\n",
      "|2016-02-29|2016-02-29 08:08:08.999|201602 |201602 |\n",
      "|2017-10-31|2017-12-31 11:59:59.123|201710 |201712 |\n",
      "|2019-11-30|2019-08-31 00:00:00.000|201911 |201908 |\n",
      "+----------+-----------------------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimesDF.\n",
    "    withColumn(\"date_ym\", date_format($\"date\", \"yyyyMM\")).\n",
    "    withColumn(\"time_ym\", date_format($\"time\", \"yyyyMM\")).\n",
    "    show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Obtenez le jour dans une semaine, le jour dans un mois et le jour dans un an à partir de la date et de l'heure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "l = List(X)\n",
       "df = [dummy: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[dummy: string]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val l = List(\"X\")\n",
    "val df = l.toDF(\"dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{dayofweek, current_date, dayofmonth, dayofyear}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|dayofweek(current_date())|\n",
      "+-------------------------+\n",
      "|                        1|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(dayofweek(current_date)).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+--------+--------+--------+--------+--------+--------+\n",
      "|date      |time                   |date_dow|time_dow|date_dom|time_dom|date_doy|time_doy|\n",
      "+----------+-----------------------+--------+--------+--------+--------+--------+--------+\n",
      "|2014-02-28|2014-02-28 10:00:00.123|6       |6       |28      |28      |59      |59      |\n",
      "|2016-02-29|2016-02-29 08:08:08.999|2       |2       |29      |29      |60      |60      |\n",
      "|2017-10-31|2017-12-31 11:59:59.123|3       |1       |31      |31      |304     |365     |\n",
      "|2019-11-30|2019-08-31 00:00:00.000|7       |7       |30      |31      |334     |243     |\n",
      "+----------+-----------------------+--------+--------+--------+--------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimesDF.\n",
    "    withColumn(\"date_dow\", dayofweek($\"date\")).\n",
    "    withColumn(\"time_dow\", dayofweek($\"time\")).\n",
    "    withColumn(\"date_dom\", dayofmonth($\"date\")).\n",
    "    withColumn(\"time_dom\", dayofmonth($\"time\")).\n",
    "    withColumn(\"date_doy\", dayofyear($\"date\")).\n",
    "    withColumn(\"time_doy\", dayofyear($\"time\")).\n",
    "    show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Obtenez les informations de temps au format yyyyMMddHHmmss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+--------------+\n",
      "|date      |time                   |time_ts       |\n",
      "+----------+-----------------------+--------------+\n",
      "|2014-02-28|2014-02-28 10:00:00.123|20140228100000|\n",
      "|2016-02-29|2016-02-29 08:08:08.999|20160229080808|\n",
      "|2017-10-31|2017-12-31 11:59:59.123|20171231115959|\n",
      "|2019-11-30|2019-08-31 00:00:00.000|20190831000000|\n",
      "+----------+-----------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimesDF.\n",
    "    withColumn(\"time_ts\", date_format($\"time\", \"yyyyMMddHHmmss\")).\n",
    "    show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+----------+-----------+\n",
      "|date      |time                   |date_us   |date_f     |\n",
      "+----------+-----------------------+----------+-----------+\n",
      "|2014-02-28|2014-02-28 10:00:00.123|02-28-2014|28-Feb-2014|\n",
      "|2016-02-29|2016-02-29 08:08:08.999|02-29-2016|29-Feb-2016|\n",
      "|2017-10-31|2017-12-31 11:59:59.123|10-31-2017|31-Oct-2017|\n",
      "|2019-11-30|2019-08-31 00:00:00.000|11-30-2019|30-Nov-2019|\n",
      "+----------+-----------------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimesDF.\n",
    "    withColumn(\"date_us\", date_format($\"date\", \"MM-dd-yyyy\")).\n",
    "    withColumn(\"date_f\", date_format($\"date\", \"dd-MMM-yyyy\")).\n",
    "    show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
