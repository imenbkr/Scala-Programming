{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des données de colonnes\n",
    "\n",
    "Dans le cadre de ce module, nous explorerons les fonctions disponibles sous `org.apache.spark.sql.functions` pour dériver de nouvelles valeurs à partir de valeurs de colonnes existantes dans un Data Frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction aux fonctions prédéfinies\n",
    "\n",
    "Les données dans les colonnes sont généralement traitées à l'aide de fonctions issues de `org.apache.spark.sql.functions`. Nous allons comprendre les détails de ces fonctions en détail.\n",
    "* Récapitulons les Fonctions ou les API pour traiter les Data Frames.\n",
    " * Projection - `select` ou `withColumn`\n",
    " * Filtrage - `filter` ou `where`\n",
    " * Regrouper les données par clé et effectuer des agrégations - `groupBy`\n",
    " * Tri des données - `sort` ou `orderBy` \n",
    "* Nous pouvons transmettre des noms de colonnes, des littéraux ou des expressions à toutes les API Data Frame.\n",
    "* Les expressions comprennent des opérations arithmétiques, des transformations utilisant des fonctions de `org.apache.spark.sql.functions`.\n",
    "* Il y a environ 300 fonctions sous `org.apache.spark.sql.functions`.\n",
    "* Nous parlerons de certaines des fonctions importantes utilisées pour la manipulation de chaînes, la manipulation de dates, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@324087d6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@324087d6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession.\n",
    "    builder.\n",
    "    appName(\"Processing Column Data\").\n",
    "    master(\"local[*]\").\n",
    "    getOrCreate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici un exemple de création de Data Frame à l'aide d'une collection d'employés. Nous utiliserons ce Data Frame pour explorer toutes les fonctions importantes pour traiter en détail les données des colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employees = List((1,Scott,Tiger,1000.0,united states,+1 123 456 7890,123 45 6789), (2,Henry,Ford,1250.0,India,+91 234 567 8901,456 78 9123), (3,Nick,Junior,750.0,united KINGDOM,+44 111 111 1111,222 33 4444), (4,Bill,Gomes,1500.0,AUSTRALIA,+61 987 654 3210,789 12 6118))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "List((1,Scott,Tiger,1000.0,united states,+1 123 456 7890,123 45 6789), (2,Henry,Ford,1250.0,India,+91 234 567 8901,456 78 9123), (3,Nick,Junior,750.0,united KINGDOM,+44 111 111 1111,222 33 4444), (4,Bill,Gomes,1500.0,AUSTRALIA,+61 987 654 3210,789 12 6118))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val employees = List((1, \"Scott\", \"Tiger\", 1000.0, \n",
    "                      \"united states\", \"+1 123 456 7890\", \"123 45 6789\"\n",
    "                     ),\n",
    "                     (2, \"Henry\", \"Ford\", 1250.0, \n",
    "                      \"India\", \"+91 234 567 8901\", \"456 78 9123\"\n",
    "                     ),\n",
    "                     (3, \"Nick\", \"Junior\", 750.0, \n",
    "                      \"united KINGDOM\", \"+44 111 111 1111\", \"222 33 4444\"\n",
    "                     ),\n",
    "                     (4, \"Bill\", \"Gomes\", 1500.0, \n",
    "                      \"AUSTRALIA\", \"+61 987 654 3210\", \"789 12 6118\"\n",
    "                     )\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employees.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employeesDF = [employee_id: int, first_name: string ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[employee_id: int, first_name: string ... 5 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val employeesDF = employees.\n",
    "    toDF(\"employee_id\", \"first_name\",\n",
    "         \"last_name\", \"salary\",\n",
    "         \"nationality\", \"phone_number\",\n",
    "         \"ssn\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: integer (nullable = false)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- salary: double (nullable = false)\n",
      " |-- nationality: string (nullable = true)\n",
      " |-- phone_number: string (nullable = true)\n",
      " |-- ssn: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n",
      "|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          4|      Bill|    Gomes|1500.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catégories de fonctions\n",
    "\n",
    "Il existe environ 300 fonctions sous org.apache.spark.sql.functions. À un niveau supérieur, ils peuvent être regroupés en quelques catégories.\n",
    "* Fonctions de manipulation de chaînes\n",
    " * Conversion de la casse - `lower`,  `upper`\n",
    " * Obtenir la longueur -  `length`\n",
    " * Extraction de sous-chaînes - `substring`, `split`\n",
    " * Trimming - `trim`, `ltrim`, `rtrim`\n",
    " * Padding - `lpad`, `rpad`\n",
    " * Concaténer des chaînes - `concat`\n",
    "* Fonctions de manipulation de date\n",
    " * Obtenir la date et l'heure actuelles - `current_date`, `current_timestamp`\n",
    " * Arithmétique des dates - `date_add`, `date_sub`, `datediff`, `months_between`, `add_months`, `next_day`\n",
    " * Date ou heure de début et de fin - `last_day`, `trunc`, `date_trunc`\n",
    " * Mise en forme de date - `date_format`\n",
    " * Extraction d'informations - `dayofyear`, `dayofmonth`, `dayofweek`, `year`, `month`\n",
    "* Fonctions d'agrégation\n",
    " * `count`, `countDistinct`\n",
    " * `sum`, `avg`\n",
    " * `min`, `max`\n",
    "* Autres fonctions - Nous explorerons en fonction des cas d'utilisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions spéciales - col and lit\n",
    "\n",
    "Comprenons les fonctions spéciales telles que col et lit.\n",
    "\n",
    "* Pour les API Data Frame telles que `select`, `groupBy`, `orderBy` etc nous pouvons passer des noms de colonnes sous forme de chaînes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|     Scott|    Tiger|\n",
      "|     Henry|     Ford|\n",
      "|      Nick|   Junior|\n",
      "|      Bill|    Gomes|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Alternative by passing column names as strings.\n",
    "employeesDF.\n",
    "    select(\"first_name\", \"last_name\").\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Alternative using col function\n",
    "// $ is shorthand operator for col from implicits\n",
    "import org.apache.spark.sql.functions.col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|     Scott|    Tiger|\n",
      "|     Henry|     Ford|\n",
      "|      Nick|   Junior|\n",
      "|      Bill|    Gomes|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.\n",
    "    select(col(\"first_name\"), col(\"last_name\")).\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "// to use operators such as $ in place of functions like col\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|     Scott|    Tiger|\n",
      "|     Henry|     Ford|\n",
      "|      Nick|   Junior|\n",
      "|      Bill|    Gomes|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.\n",
    "    select($\"first_name\", $\"last_name\").\n",
    "    show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* S'il n'y a aucune transformation sur une colonne dans une fonction, nous pouvons transmettre tous les noms de colonne sous forme de chaînes.\n",
    "* Sinon, nous devons transmettre toutes les colonnes en tant que type de colonne en utilisant la fonction col ou son opérateur abrégé $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|   nationality|count|\n",
      "+--------------+-----+\n",
      "| united states|    1|\n",
      "|         India|    1|\n",
      "|united KINGDOM|    1|\n",
      "|     AUSTRALIA|    1|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Passing columns as part of groupBy\n",
    "employeesDF.\n",
    "    groupBy(\"nationality\").\n",
    "    count.\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|upper(nationality)|count|\n",
      "+------------------+-----+\n",
      "|     UNITED STATES|    1|\n",
      "|             INDIA|    1|\n",
      "|    UNITED KINGDOM|    1|\n",
      "|         AUSTRALIA|    1|\n",
      "+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.\n",
    "    groupBy(upper(col(\"nationality\"))).\n",
    "    count.\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n",
      "|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          4|      Bill|    Gomes|1500.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Passing columns as part of orderBy or sort\n",
    "employeesDF.\n",
    "    orderBy(\"employee_id\").\n",
    "    show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cependant, si nous voulons appliquer une transformation à l'aide de fonctions, il ne suffira pas de transmettre des noms de colonne sous forme de chaînes à certaines fonctions. Nous devons les passer comme type de colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "Unknown Error",
     "evalue": "<console>:34: error: type mismatch;\n found   : String(\"first_name\")\n required: org.apache.spark.sql.Column\n           select(upper(\"first_name\")).\n                        ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "//This code fails as upper is not valid function on string\n",
    "employeesDF.\n",
    "    select(upper(\"first_name\")).\n",
    "    show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `col` est la fonction qui convertira le nom de la colonne du type chaîne en type **Colonne**. Nous pouvons également faire référence aux noms de colonne en tant que type ** Colonne ** en utilisant le nom du Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|upper(first_name)|\n",
      "+-----------------+\n",
      "|            SCOTT|\n",
      "|            HENRY|\n",
      "|             NICK|\n",
      "|             BILL|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Alternate using $ and upper\n",
    "employeesDF.\n",
    "    select(upper($\"first_name\")).\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|upper(nationality)|count|\n",
      "+------------------+-----+\n",
      "|     UNITED STATES|    1|\n",
      "|             INDIA|    1|\n",
      "|    UNITED KINGDOM|    1|\n",
      "|         AUSTRALIA|    1|\n",
      "+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Using as part of groupBy\n",
    "employeesDF.\n",
    "    groupBy(upper($\"nationality\")).\n",
    "    count.\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|          4|      Bill|    Gomes|1500.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Using as part of orderBy\n",
    "employeesDF.\n",
    "    orderBy(upper($\"nationality\")).\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|          4|      Bill|    Gomes|1500.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Alternative - we can also refer column names using Data Frame like this\n",
    "employeesDF.\n",
    "    orderBy(upper(employeesDF(\"nationality\"))).\n",
    "    show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parfois, nous souhaitons ajouter un littéral aux valeurs des colonnes. Par exemple, nous pourrions vouloir concaténer first_name et last_name séparés par une virgule et un espace entre eux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Les approches ci-dessous échouent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "Unknown Error",
     "evalue": "<console>:34: error: type mismatch;\n found   : String(\", \")\n required: org.apache.spark.sql.Column\n           select(concat($\"first_name\", \", \", $\"last_name\")).\n                                        ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "employeesDF.\n",
    "    select(concat($\"first_name\", \", \", $\"last_name\")).\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "Unknown Error",
     "evalue": "<console>:35: error: type mismatch;\n found   : String(\", \")\n required: org.apache.spark.sql.Column\n           select(concat(col(\"first_name\"), \", \", col(\"last_name\"))).\n                                            ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "// Same as above\n",
    "employeesDF.\n",
    "    select(concat(col(\"first_name\"), \", \", col(\"last_name\"))).\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "Unknown Error",
     "evalue": "<console>:35: error: type mismatch;\n found   : String(\", \")\n required: org.apache.spark.sql.Column\n           select(concat(employeesDF(\"first_name\"), \", \", employeesDF(\"last_name\"))).\n                                                    ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "// Referring columns using Data Frame\n",
    "employeesDF.\n",
    "    select(concat(employeesDF(\"first_name\"), \", \", employeesDF(\"last_name\"))).\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "Unknown Error",
     "evalue": "<console>:34: error: type mismatch;\n found   : String(\"first_name\")\n required: org.apache.spark.sql.Column\n           select(concat(\"first_name\", \", \", \"last_name\")).\n                         ^\n<console>:34: error: type mismatch;\n found   : String(\", \")\n required: org.apache.spark.sql.Column\n           select(concat(\"first_name\", \", \", \"last_name\")).\n                                       ^\n<console>:34: error: type mismatch;\n found   : String(\"last_name\")\n required: org.apache.spark.sql.Column\n           select(concat(\"first_name\", \", \", \"last_name\")).\n                                             ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "employeesDF.\n",
    "    select(concat(\"first_name\", \", \", \"last_name\")).\n",
    "    show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Si nous passons les littéraux directement sous forme de chaîne ou de type numérique, cela échouera. Nous devons convertir les littéraux en type de colonne en utilisant la fonction `lit`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Using lit to use literals to derive new expressions\n",
    "import org.apache.spark.sql.functions.{concat, col, lit}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+\n",
      "|concat(first_name, , , last_name)|\n",
      "+---------------------------------+\n",
      "|                     Scott, Tiger|\n",
      "|                      Henry, Ford|\n",
      "|                     Nick, Junior|\n",
      "|                      Bill, Gomes|\n",
      "+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.\n",
    "    select(concat(col(\"first_name\"), lit(\", \"), col(\"last_name\"))).\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|   Full Name|\n",
      "+------------+\n",
      "|Scott, Tiger|\n",
      "| Henry, Ford|\n",
      "|Nick, Junior|\n",
      "| Bill, Gomes|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.\n",
    "    select(concat($\"first_name\", lit(\", \"), employeesDF(\"last_name\")) alias (\"Full Name\")).\n",
    "    show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulation de chaînes - Conversion de casse et Longueur de chaîne\n",
    "Vérifions les fonctions qui peuvent convertir la casse des valeurs de colonne qui sont de type chaîne et obtenir également la longueur.\n",
    "* Convertir tous les caractères alphabétiques d'une chaîne en **majuscules** - `upper`\n",
    "* Convertir tous les caractères alphabétiques d'une chaîne en **lowercase** - `lower`\n",
    "* Convertir le premier caractère d'une chaîne en **uppercase** - `initcap`\n",
    "* Obtenir le **nombre de caractères dans une chaîne** - `length`\n",
    "* Toutes les 4 fonctions prennent un argument de type colonne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application\n",
    "\n",
    "\n",
    "* Utilisez les données des employés et créez un Data Frame.\n",
    "* Appliquez les 4 fonctions sur **nationality** et voyez les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{col, upper, lower, initcap, length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+-----------------+-----------------+-------------------+------------------+\n",
      "|employee_id|   nationality|nationality_upper|nationality_lower|nationality_initcap|nationality_length|\n",
      "+-----------+--------------+-----------------+-----------------+-------------------+------------------+\n",
      "|          1| united states|    UNITED STATES|    united states|      United States|                13|\n",
      "|          2|         India|            INDIA|            india|              India|                 5|\n",
      "|          3|united KINGDOM|   UNITED KINGDOM|   united kingdom|     United Kingdom|                14|\n",
      "|          4|     AUSTRALIA|        AUSTRALIA|        australia|          Australia|                 9|\n",
      "+-----------+--------------+-----------------+-----------------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.\n",
    "    select(\"employee_id\", \"nationality\").\n",
    "    withColumn(\"nationality_upper\", upper(col(\"nationality\"))).\n",
    "    withColumn(\"nationality_lower\", lower($\"nationality\")).\n",
    "    withColumn(\"nationality_initcap\", initcap(employeesDF(\"nationality\"))).\n",
    "    withColumn(\"nationality_length\", length(col(\"nationality\"))).\n",
    "    show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulation de chaînes - substring\n",
    "\n",
    "Nous pouvons extraire des sous-chaînes en utilisant la fonction  `substring`.\n",
    "* Si nous traitons des **colonnes de longueur fixe**, nous utilisons `substring` pour extraire les informations.\n",
    "* Voici quelques exemples de **colonnes de longueur fixe** et les cas d'utilisation pour lesquels nous extrayons généralement des informations.\n",
    " * Numéro de sécurité sociale à 9 chiffres. Nous extrayons généralement les 4 derniers chiffres et les fournissons aux applications de télévérification.\n",
    " * Numéro de carte de crédit à 16 chiffres. Nous utilisons généralement les 4 premiers chiffres pour identifier le fournisseur de carte de crédit et les 4 derniers chiffres aux fins de la télévérification.\n",
    "\n",
    "* `substring` La fonction prend 3 arguments, **colonne**, **position**, **longueur**. Nous pouvons également fournir la position à partir de la fin en transmettant une valeur négative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s = Hello World\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Hello World"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val s = \"Hello World\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hello"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.substring(0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ell"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.substring(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "World"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.substring(6, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "l = List(X)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "List(X)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val l = List(\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [dummy: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[dummy: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = l.toDF(\"dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "Unknown Error",
     "evalue": "<console>:24: error: not found: value df\n       df.show\n       ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "df.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dummy: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{substring, lit}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Resultat|\n",
      "+--------+\n",
      "|   World|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(substring(lit(\"Hello World\"), 7, 5)).\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Resultat|\n",
      "+--------+\n",
      "|   World|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(substring(lit(\"Hello World\"), -5, 5) alias (\"Resultat\")).\n",
    "    show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application\n",
    "\n",
    "Effectuons quelques traitements pour extraire des informations à partir de chaînes de longueur fixe.\n",
    "* Créez une liste pour les employés avec nom, ssn et numéro de téléphone.\n",
    "* Format SSN **3 2 4** - Longueur fixe à 9 chiffres\n",
    "* Format du numéro de téléphone - L'indicatif du pays est variable et le numéro de téléphone restant comporte 10 chiffres :\n",
    " * Code du pays - un à 3 chiffres\n",
    " * Indicatif régional - 3 chiffres\n",
    " * Préfixe du numéro de téléphone - 3 chiffres\n",
    " * Numéro de téléphone restant - 4 chiffres\n",
    " * Toutes les 4 parties sont séparées par des espaces\n",
    "* Créez un Dataframe avec les noms de colonne name, ssn et phone_number\n",
    "* Extraire les 4 derniers chiffres du numéro de téléphone.\n",
    "* Extraire les 4 derniers chiffres du SSN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employees = List((1,Scott,Tiger,1000.0,united states,+1 123 456 7890,123 45 6789), (2,Henry,Ford,1250.0,India,+91 234 567 8901,456 78 9123), (3,Nick,Junior,750.0,united KINGDOM,+44 111 111 1111,222 33 4444), (4,Bill,Gomes,1500.0,AUSTRALIA,+61 987 654 3210,789 12 6118))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "List((1,Scott,Tiger,1000.0,united states,+1 123 456 7890,123 45 6789), (2,Henry,Ford,1250.0,India,+91 234 567 8901,456 78 9123), (3,Nick,Junior,750.0,united KINGDOM,+44 111 111 1111,222 33 4444), (4,Bill,Gomes,1500.0,AUSTRALIA,+61 987 654 3210,789 12 6118))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val employees = List((1, \"Scott\", \"Tiger\", 1000.0, \n",
    "                      \"united states\", \"+1 123 456 7890\", \"123 45 6789\"\n",
    "                     ),\n",
    "                     (2, \"Henry\", \"Ford\", 1250.0, \n",
    "                      \"India\", \"+91 234 567 8901\", \"456 78 9123\"\n",
    "                     ),\n",
    "                     (3, \"Nick\", \"Junior\", 750.0, \n",
    "                      \"united KINGDOM\", \"+44 111 111 1111\", \"222 33 4444\"\n",
    "                     ),\n",
    "                     (4, \"Bill\", \"Gomes\", 1500.0, \n",
    "                      \"AUSTRALIA\", \"+61 987 654 3210\", \"789 12 6118\"\n",
    "                     )\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employeesDF = [employee_id: int, first_name: string ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[employee_id: int, first_name: string ... 5 more fields]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val employeesDF = employees.\n",
    "    toDF(\"employee_id\", \"first_name\",\n",
    "         \"last_name\", \"salary\",\n",
    "         \"nationality\", \"phone_number\",\n",
    "         \"ssn\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n",
      "|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          4|      Bill|    Gomes|1500.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.substring\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|phone_last4|ssn_last4|\n",
      "+-----------+---------+\n",
      "|       7890|     6789|\n",
      "|       8901|     9123|\n",
      "|       1111|     4444|\n",
      "|       3210|     6118|\n",
      "+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.\n",
    "    select(substring($\"phone_number\", -4, 4) alias (\"phone_last4\"), \n",
    "           substring($\"ssn\", -4, 4) alias (\"ssn_last4\")\n",
    "          ).\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+-----------+-----------+---------+\n",
      "|employee_id|    phone_number|        ssn|phone_last4|ssn_last4|\n",
      "+-----------+----------------+-----------+-----------+---------+\n",
      "|          1| +1 123 456 7890|123 45 6789|       7890|     6789|\n",
      "|          2|+91 234 567 8901|456 78 9123|       8901|     9123|\n",
      "|          3|+44 111 111 1111|222 33 4444|       1111|     4444|\n",
      "|          4|+61 987 654 3210|789 12 6118|       3210|     6118|\n",
      "+-----------+----------------+-----------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.\n",
    "    select(\"employee_id\", \"phone_number\", \"ssn\").\n",
    "    withColumn(\"phone_last4\", substring($\"phone_number\", -4, 4).cast(\"int\")).\n",
    "    withColumn(\"ssn_last4\", substring($\"ssn\", 8, 4).cast(\"int\")).\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+-----------+-----------+---------+\n",
      "|employee_id|    phone_number|        ssn|phone_last4|ssn_last4|\n",
      "+-----------+----------------+-----------+-----------+---------+\n",
      "|          1| +1 123 456 7890|123 45 6789|       7890|     6789|\n",
      "|          2|+91 234 567 8901|456 78 9123|       8901|     9123|\n",
      "|          3|+44 111 111 1111|222 33 4444|       1111|     4444|\n",
      "|          4|+61 987 654 3210|789 12 6118|       3210|     6118|\n",
      "+-----------+----------------+-----------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.\n",
    "    select($\"employee_id\", $\"phone_number\", $\"ssn\", \n",
    "           substring($\"phone_number\", -4, 4).cast(\"int\").alias(\"phone_last4\"),\n",
    "           substring($\"ssn\", 8, 4).cast(\"int\").alias(\"ssn_last4\")\n",
    "          ).\n",
    "    show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulation de chaînes - split\n",
    "Voyons comment nous pouvons extraire des sous-chaînes en utilisant `split`.\n",
    "* Si nous traitons des **colonnes de longueur variable** avec un **délimiteur**, nous utilisons `split` pour extraire les informations.\n",
    "* oici quelques exemples de **colonnes de longueur variable** et les cas d'utilisation pour lesquels nous extrayons généralement des informations.\n",
    " * Adresse où nous stockons le numéro de maison, le nom de la rue, la ville, l'état et le code postal séparés par des virgules. Nous voudrons peut-être extraire la ville et l'état pour les rapports démographiques.\n",
    "* `split` prend 2 arguments, **colonne** et **délimiteur**.\n",
    "* `split` convertit chaque chaîne en tableau et nous pouvons accéder aux éléments en utilisant l'index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [Dummy: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Dummy: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = List(\"X\").toDF(\"Dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{split, lit}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|titre                         |\n",
      "+------------------------------+\n",
      "|[Hello, World,, how, are, you]|\n",
      "+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(split(lit(\"Hello World, how are you\"), \" \") as \"titre\").\n",
    "    show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Split|\n",
      "+-----+\n",
      "|how  |\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(split(lit(\"Hello World, how are you\"), \" \")(2) alias \"Split\").\n",
    "    show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application\n",
    "Effectuons quelques traitements pour extraire des informations à partir de chaînes de longueur fixe ainsi que de chaînes de longueur variable délimitées.\n",
    "* Créez une liste pour les employés avec nom, ssn et numéro de téléphone.\n",
    "* Format du numéro de téléphone - L'indicatif du pays est variable et le numéro de téléphone restant comporte 10 chiffres :\n",
    " * Code du pays - un à 3 chiffres\n",
    " * Indicatif régional - 3 chiffres\n",
    " * Préfixe du numéro de téléphone - 3 chiffres\n",
    " * Numéro de téléphone restant - 4 chiffres\n",
    " * Toutes les 4 parties sont séparées par des espaces\n",
    "* Créez un Dataframe avec les noms de colonne name, ssn et phone_number\n",
    "* Extraire les 4 derniers chiffres du numéro de téléphone.\n",
    "* Extraire les 4 derniers chiffres du SSN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.split\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+-----------+---------+-----------+---------+\n",
      "|employee_id|    phone_number|        ssn|area_code|phone_last4|ssn_last4|\n",
      "+-----------+----------------+-----------+---------+-----------+---------+\n",
      "|          1| +1 123 456 7890|123 45 6789|      123|       7890|     6789|\n",
      "|          2|+91 234 567 8901|456 78 9123|      234|       8901|     9123|\n",
      "|          3|+44 111 111 1111|222 33 4444|      111|       1111|     4444|\n",
      "|          4|+61 987 654 3210|789 12 6118|      987|       3210|     6118|\n",
      "+-----------+----------------+-----------+---------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.\n",
    "    select(\"employee_id\", \"phone_number\", \"ssn\").\n",
    "    withColumn(\"area_code\", split($\"phone_number\", \" \")(1).cast(\"int\")).\n",
    "    withColumn(\"phone_last4\", split($\"phone_number\", \" \")(3).cast(\"int\")).\n",
    "    withColumn(\"ssn_last4\", split($\"ssn\", \" \")(2).cast(\"int\")).\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+-----------+---------+----------+---------+\n",
      "|employee_id|    phone_number|        ssn|area_code|phone_last|ssn_last4|\n",
      "+-----------+----------------+-----------+---------+----------+---------+\n",
      "|          1| +1 123 456 7890|123 45 6789|      123|      7890|     6789|\n",
      "|          2|+91 234 567 8901|456 78 9123|      234|      8901|     9123|\n",
      "|          3|+44 111 111 1111|222 33 4444|      111|      1111|     4444|\n",
      "|          4|+61 987 654 3210|789 12 6118|      987|      3210|     6118|\n",
      "+-----------+----------------+-----------+---------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.\n",
    "    select($\"employee_id\", $\"phone_number\", $\"ssn\", \n",
    "           split($\"phone_number\", \" \")(1).cast(\"int\").alias(\"area_code\"),\n",
    "           split($\"phone_number\", \" \")(3).cast(\"int\").alias(\"phone_last\"),\n",
    "           split($\"ssn\", \" \")(2).cast(\"int\").alias(\"ssn_last4\")\n",
    "          ).\n",
    "    show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulation de chaînes - Concaténation de chaînes\n",
    "Voyons comment concaténer des chaînes à l'aide de la fonction `concat`.\n",
    "* Nous pouvons passer un nombre variable de chaînes à la fonction `concat`.\n",
    "* Il renverra une chaîne concaténant toutes les chaînes.\n",
    "* Si nous devons concaténer un littéral entre les chaînes, nous devons utiliser la fonction `lit`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Créez une nouvelle colonne nommée **full_name** en concaténant **first_name** et **last_name**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{concat, lit}\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+--------------+----------------+-----------+----------+\n",
      "|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn| full_name|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+----------+\n",
      "|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|ScottTiger|\n",
      "|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123| HenryFord|\n",
      "|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|NickJunior|\n",
      "|          4|      Bill|    Gomes|1500.0|     AUSTRALIA|+61 987 654 3210|789 12 6118| BillGomes|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.\n",
    "    withColumn(\"full_name\", concat($\"first_name\", $\"last_name\")).\n",
    "    show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ajoutez une **virgule suivie d'un espace** entre **first_name** et **last_name**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+--------------+----------------+-----------+------------+\n",
      "|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|   full_name|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+------------+\n",
      "|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|Scott, Tiger|\n",
      "|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123| Henry, Ford|\n",
      "|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|Nick, Junior|\n",
      "|          4|      Bill|    Gomes|1500.0|     AUSTRALIA|+61 987 654 3210|789 12 6118| Bill, Gomes|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.\n",
    "    withColumn(\"full_name\", concat($\"first_name\", lit(\", \"), $\"last_name\")).\n",
    "    show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulation de chaînes - Padding\n",
    "Voyons comment remplir des caractères au début ou à la fin des chaînes.\n",
    "* Nous complétons généralement les caractères pour créer des valeurs ou des enregistrements de longueur fixe.\n",
    "* Les valeurs ou enregistrements de longueur fixe sont largement utilisés dans les systèmes basés sur les mainframes.\n",
    "* La longueur de chaque champ dans les enregistrements de longueur fixe est prédéterminée et si la valeur du champ est inférieure à la longueur prédéterminée, nous remplissons avec un caractère standard.\n",
    "* En termes de champs numériques, nous remplissons avec zéro sur le côté gauche ou avant. Pour les champs non numériques, nous remplissons avec un caractère standard à la fin ou à droite.\n",
    "* Nous utilisons `lpad` pour remplir une chaîne avec un caractère spécifique en tête ou à gauche et `rpad` pour remplir en fin ou à droite.\n",
    "* Lpad et rpad, prennent 3 arguments - colonne ou expression, longueur désirée et le caractère de remplissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [dummy: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[dummy: string]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = List(\"X\").toDF(\"dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{lit, lpad}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|     dummy|\n",
      "+----------+\n",
      "|-----Hello|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(lpad(lit(\"Hello\"), 10, \"-\").alias(\"dummy\")).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|dummy|\n",
      "+-----+\n",
      "|   02|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(lpad(lit(2), 2, \"0\").alias(\"dummy\")).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application\n",
    "\n",
    "Effectuons simple application pour comprendre comment utiliser les fonctions de remplissage pour convertir nos données en enregistrements de longueur fixe.\n",
    "\n",
    "* Prenons le dataframe **employeesDF**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Utilisez les fonctions ** pad ** pour convertir chacun des champs en longueur fixe puis les concaténer. Voici les détails pour chacun des champs.\n",
    " * La longueur de employee_id doit être de 5 caractères et doit être complétée par des zéros.\n",
    " * La longueur du prénom et du nom doit être de 10 caractères et doit être complétée par - sur le côté droit.\n",
    " * La longueur du salaire doit être de 10 caractères et doit être complétée par des zéros.\n",
    " * La longueur de la nationalité doit être de 15 caractères et doit être complétée par - sur le côté droit.\n",
    " * La longueur du numéro de téléphone doit être de 17 caractères et doit être complétée par - sur le côté droit.\n",
    " * La longueur du ssn peut être laissée telle quelle. C'est 11 caractères.\n",
    " \n",
    "* Créez un nouveau Dataframe **empFixedDF** avec le nom de colonne **employee**. Prévisualisez les données en désactivant la troncature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{lpad, rpad, concat}\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "empFixedDF = [employee: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[employee: string]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val empFixedDF = employeesDF.select(\n",
    "    concat(\n",
    "        lpad($\"employee_id\", 5, \"0\"),\n",
    "        rpad($\"first_name\", 10, \"-\"),\n",
    "        rpad($\"last_name\", 10, \"-\"),\n",
    "        lpad($\"salary\", 10, \"0\"),\n",
    "        rpad($\"nationality\", 15, \"-\"),\n",
    "        rpad($\"phone_number\", 17, \"-\"),\n",
    "        $\"ssn\"\n",
    "    ).alias(\"employee\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------+\n",
      "|employee                                                                      |\n",
      "+------------------------------------------------------------------------------+\n",
      "|00001Scott-----Tiger-----00001000.0united states--+1 123 456 7890--123 45 6789|\n",
      "|00002Henry-----Ford------00001250.0India----------+91 234 567 8901-456 78 9123|\n",
      "|00003Nick------Junior----00000750.0united KINGDOM-+44 111 111 1111-222 33 4444|\n",
      "|00004Bill------Gomes-----00001500.0AUSTRALIA------+61 987 654 3210-789 12 6118|\n",
      "+------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empFixedDF.show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulation de chaînes - c\n",
    "Voyons comment supprimer les caractères indésirables de début et de fin  autour d'une chaîne.\n",
    "* Nous utilisons généralement le Trimming pour supprimer les caractères inutiles des enregistrements de longueur fixe.\n",
    "* Les enregistrements de longueur fixe sont largement utilisés.\n",
    "* Dans le cadre d'un traitement, nous pouvons souhaiter supprimer les caractères de début ou de fin tels que 0 dans le cas de types numériques et d'espace ou certains caractères standard dans le cas de types alphanumériques.\n",
    "* Les fonctions de trimming Spark prennent la colonne comme argument et suppriment par defaut les espaces de début ou de fin.\n",
    "* Supprimer les espaces vers la gauche - `ltrim`\n",
    "* Supprimer les espaces vers la droite - `rtrim`\n",
    "* Supprimer les espaces des deux côtés - `trim`\n",
    "* Nous pouvons également couper d'autres caractères que les espaces en utilisant ces fonctions de coupe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{col, ltrim, rtrim, trim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "l = List(\"   Hello.    \")\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "List(\"   Hello.    \")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val l = List(\"   Hello.    \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [dummy: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[dummy: string]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = l.toDF(\"dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+--------+-----+\n",
      "|        dummy|     ltrim|   rtrim| trim|\n",
      "+-------------+----------+--------+-----+\n",
      "|   Hello.    |Hello.    |   Hello|Hello|\n",
      "+-------------+----------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"ltrim\", ltrim(col(\"dummy\"))).\n",
    "    withColumn(\"rtrim\", rtrim(rtrim(col(\"dummy\")), \".\")).\n",
    "    withColumn(\"trim\", trim(trim(col(\"dummy\")), \".\")).\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"ltrim\", ltrim(col(\"dummy\"))).\n",
    "    withColumn(\"rtrim\", rtrim(rtrim(col(\"dummy\")), \".\")).\n",
    "    withColumn(\"trim\", trim(trim(col(\"dummy\")), \".\")).\n",
    "    show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
